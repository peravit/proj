{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Bi-Directional LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNbNxzmoKcD",
        "colab_type": "text"
      },
      "source": [
        "### Bi-Directional LSTM -> POS tagging of ORCHID (Bi-LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpVsbjyY8UMR",
        "colab_type": "code",
        "outputId": "438555ff-bbb2-45cd-804e-7b0171129615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sga5ALAH1w6u",
        "colab_type": "code",
        "outputId": "cb667441-4a3e-462e-a6f5-6ab13b76d961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
        " \n",
        "print(tagged_sentences[0])\n",
        "print(\"Tagged sentences: \", len(tagged_sentences))\n",
        "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
            "Tagged sentences:  3914\n",
            "Tagged words: 100676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUnrFmQ_3Axe",
        "colab_type": "code",
        "outputId": "714c1fb4-5512-4383-a7b0-189899a16bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(np.array(sentence))\n",
        "    sentence_tags.append(np.array(tags))\n",
        " \n",
        "# Let's see how a sequence looks\n",
        " \n",
        "print(sentences[5])\n",
        "print(sentence_tags[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Lorillard' 'Inc.' ',' 'the' 'unit' 'of' 'New' 'York-based' 'Loews'\n",
            " 'Corp.' 'that' '*T*-2' 'makes' 'Kent' 'cigarettes' ',' 'stopped' 'using'\n",
            " 'crocidolite' 'in' 'its' 'Micronite' 'cigarette' 'filters' 'in' '1956'\n",
            " '.']\n",
            "['NNP' 'NNP' ',' 'DT' 'NN' 'IN' 'JJ' 'JJ' 'NNP' 'NNP' 'WDT' '-NONE-' 'VBZ'\n",
            " 'NNP' 'NNS' ',' 'VBD' 'VBG' 'NN' 'IN' 'PRP$' 'NN' 'NN' 'NNS' 'IN' 'CD'\n",
            " '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJFKs3bg3juV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_sentences, test_sentences, train_tags, test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-vrDKFj3pvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, tags = set([]), set([])\n",
        " \n",
        "for s in train_sentences:\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        " \n",
        "for ts in train_tags:\n",
        "    for t in ts:\n",
        "        tags.add(t)\n",
        " \n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        " \n",
        "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-U6tQ533UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gXCCeI138l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in train_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    train_sentences_X.append(s_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAHTnU7K4kVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in test_sentences:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        " \n",
        "    test_sentences_X.append(s_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Oz-jYd4AWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in train_tags:\n",
        "    train_tags_y.append([tag2index[t] for t in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANdo3IDT4D7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for s in test_tags:\n",
        "  test_tags_y.append([tag2index[t] for t in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nob1-H_3sxH",
        "colab_type": "code",
        "outputId": "d3fd6ab4-afd3-4788-e0e7-e2151a044efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[532, 2155, 9098, 7123, 9631, 8218, 3074, 8457, 854, 9464, 363, 6566, 7650, 6711, 5649, 9527, 8880, 3643, 6711, 5558, 9527, 8218, 3074, 7125, 854, 5327]\n",
            "[9824, 5619, 3458, 3395, 5490, 5610, 8880, 8893, 9018, 5251, 2258, 870, 6995, 5610, 8880, 5771, 426, 4778, 6504, 4442, 4778, 6566, 8880, 9205, 5019, 4778, 3806, 7655, 532, 426, 5327]\n",
            "[32, 44, 21, 43, 38, 42, 5, 5, 18, 18, 21, 38, 40, 4, 38, 38, 32, 40, 4, 4, 38, 42, 5, 5, 18, 19]\n",
            "[24, 43, 38, 13, 35, 38, 32, 4, 4, 4, 36, 29, 18, 38, 32, 40, 4, 2, 25, 4, 2, 38, 32, 29, 4, 2, 37, 28, 32, 4, 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb39fkwO3u9M",
        "colab_type": "code",
        "outputId": "11179063-1a54-40b0-8da6-82a5c15c0178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7smQpdeS5jYN",
        "colab_type": "code",
        "outputId": "5cfa4d7f-4356-436f-d1b9-2139f8a3fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vvR3iIi5m6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences_X = pad_sequences(train_sentences_X,\n",
        "                                  maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X,\n",
        "                                 maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y,\n",
        "                             maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y,\n",
        "                            maxlen=MAX_LENGTH, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCe3_AIc5tgA",
        "colab_type": "code",
        "outputId": "c31f8e82-3e8a-46c4-ddcd-07d078a8b290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(train_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(test_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 532 2155 9098 7123 9631 8218 3074 8457  854 9464  363 6566 7650 6711\n",
            " 5649 9527 8880 3643 6711 5558 9527 8218 3074 7125  854 5327    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "[9824 5619 3458 3395 5490 5610 8880 8893 9018 5251 2258  870 6995 5610\n",
            " 8880 5771  426 4778 6504 4442 4778 6566 8880 9205 5019 4778 3806 7655\n",
            "  532  426 5327    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "[32 44 21 43 38 42  5  5 18 18 21 38 40  4 38 38 32 40  4  4 38 42  5  5\n",
            " 18 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n",
            "[24 43 38 13 35 38 32  4  4  4 36 29 18 38 32 40  4  2 25  4  2 38 32 29\n",
            "  4  2 37 28 32  4 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bPYW6I29S6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        " \n",
        "def ignore_class_accuracy(to_ignore=0):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        " \n",
        "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1g9s6YP5v7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmC7Jlvo51bz",
        "colab_type": "code",
        "outputId": "146e927a-13c2-4ddd-a37c-b136c2266caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
        "model.add(Embedding(len(word2index), 128))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(tag2index))))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6761TX-53Ls",
        "colab_type": "code",
        "outputId": "9dcabccc-b6e9-4e6b-a1b7-0b7c214ff5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(0.001),\n",
        "              metrics=['accuracy', ignore_class_accuracy(0)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7vS8Bkh55QU",
        "colab_type": "code",
        "outputId": "16bd330c-3d39-4c12-80ae-e8944294f259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 271, 128)          1291776   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 271, 512)          788480    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 271, 47)           24111     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 271, 47)           0         \n",
            "=================================================================\n",
            "Total params: 2,104,367\n",
            "Trainable params: 2,104,367\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxlulDp-57Ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eoX8mzs6Bka",
        "colab_type": "code",
        "outputId": "cb09abe3-6714-48e4-f0c0-32466140a67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
        "print(cat_train_tags_y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67cfw_26DX2",
        "colab_type": "code",
        "outputId": "0ba9ef9e-cab9-405c-8a12-114e8f69d8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_sentences_X,\n",
        "                    to_categorical(train_tags_y, len(tag2index)),\n",
        "                    batch_size=128,\n",
        "                    epochs=40,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 2504 samples, validate on 627 samples\n",
            "Epoch 1/40\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2504/2504 [==============================] - 22s 9ms/step - loss: 1.3105 - acc: 0.8584 - ignore_accuracy: 0.0210 - val_loss: 0.3892 - val_acc: 0.9089 - val_ignore_accuracy: 0.1309\n",
            "Epoch 2/40\n",
            "2504/2504 [==============================] - 16s 7ms/step - loss: 0.3483 - acc: 0.9046 - ignore_accuracy: 0.0488 - val_loss: 0.3133 - val_acc: 0.9083 - val_ignore_accuracy: 0.0000e+00\n",
            "Epoch 3/40\n",
            "2504/2504 [==============================] - 16s 7ms/step - loss: 0.3192 - acc: 0.9080 - ignore_accuracy: 0.0906 - val_loss: 0.3009 - val_acc: 0.9180 - val_ignore_accuracy: 0.1313\n",
            "Epoch 4/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.3084 - acc: 0.9155 - ignore_accuracy: 0.1307 - val_loss: 0.2932 - val_acc: 0.9205 - val_ignore_accuracy: 0.1391\n",
            "Epoch 5/40\n",
            "2504/2504 [==============================] - 16s 7ms/step - loss: 0.2999 - acc: 0.9165 - ignore_accuracy: 0.1337 - val_loss: 0.2830 - val_acc: 0.9202 - val_ignore_accuracy: 0.1376\n",
            "Epoch 6/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.2922 - acc: 0.9160 - ignore_accuracy: 0.1310 - val_loss: 0.2787 - val_acc: 0.9203 - val_ignore_accuracy: 0.1382\n",
            "Epoch 7/40\n",
            "2504/2504 [==============================] - 16s 7ms/step - loss: 0.2862 - acc: 0.9165 - ignore_accuracy: 0.1338 - val_loss: 0.2724 - val_acc: 0.9227 - val_ignore_accuracy: 0.1608\n",
            "Epoch 8/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.2803 - acc: 0.9192 - ignore_accuracy: 0.1571 - val_loss: 0.2677 - val_acc: 0.9239 - val_ignore_accuracy: 0.1723\n",
            "Epoch 9/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.2762 - acc: 0.9230 - ignore_accuracy: 0.1960 - val_loss: 0.2620 - val_acc: 0.9320 - val_ignore_accuracy: 0.2601\n",
            "Epoch 10/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.2698 - acc: 0.9299 - ignore_accuracy: 0.2666 - val_loss: 0.2562 - val_acc: 0.9351 - val_ignore_accuracy: 0.2935\n",
            "Epoch 11/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.2628 - acc: 0.9347 - ignore_accuracy: 0.3182 - val_loss: 0.2485 - val_acc: 0.9415 - val_ignore_accuracy: 0.3643\n",
            "Epoch 12/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2540 - acc: 0.9403 - ignore_accuracy: 0.3775 - val_loss: 0.2371 - val_acc: 0.9448 - val_ignore_accuracy: 0.3993\n",
            "Epoch 13/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2380 - acc: 0.9429 - ignore_accuracy: 0.4034 - val_loss: 0.2201 - val_acc: 0.9447 - val_ignore_accuracy: 0.3985\n",
            "Epoch 14/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2180 - acc: 0.9440 - ignore_accuracy: 0.4149 - val_loss: 0.2011 - val_acc: 0.9466 - val_ignore_accuracy: 0.4196\n",
            "Epoch 15/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1975 - acc: 0.9481 - ignore_accuracy: 0.4591 - val_loss: 0.1817 - val_acc: 0.9522 - val_ignore_accuracy: 0.4804\n",
            "Epoch 16/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1765 - acc: 0.9542 - ignore_accuracy: 0.5232 - val_loss: 0.1622 - val_acc: 0.9579 - val_ignore_accuracy: 0.5433\n",
            "Epoch 17/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1540 - acc: 0.9602 - ignore_accuracy: 0.5858 - val_loss: 0.1408 - val_acc: 0.9642 - val_ignore_accuracy: 0.6124\n",
            "Epoch 18/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1300 - acc: 0.9674 - ignore_accuracy: 0.6610 - val_loss: 0.1193 - val_acc: 0.9695 - val_ignore_accuracy: 0.6696\n",
            "Epoch 19/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1068 - acc: 0.9747 - ignore_accuracy: 0.7375 - val_loss: 0.0997 - val_acc: 0.9754 - val_ignore_accuracy: 0.7342\n",
            "Epoch 20/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0862 - acc: 0.9808 - ignore_accuracy: 0.7997 - val_loss: 0.0839 - val_acc: 0.9799 - val_ignore_accuracy: 0.7812\n",
            "Epoch 21/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.0737 - acc: 0.9841 - ignore_accuracy: 0.8362 - val_loss: 0.0863 - val_acc: 0.9812 - val_ignore_accuracy: 0.8110\n",
            "Epoch 22/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.0625 - acc: 0.9874 - ignore_accuracy: 0.8724 - val_loss: 0.0640 - val_acc: 0.9855 - val_ignore_accuracy: 0.8423\n",
            "Epoch 23/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0488 - acc: 0.9900 - ignore_accuracy: 0.8964 - val_loss: 0.0560 - val_acc: 0.9870 - val_ignore_accuracy: 0.8588\n",
            "Epoch 24/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0405 - acc: 0.9918 - ignore_accuracy: 0.9151 - val_loss: 0.0505 - val_acc: 0.9880 - val_ignore_accuracy: 0.8697\n",
            "Epoch 25/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.0342 - acc: 0.9932 - ignore_accuracy: 0.9292 - val_loss: 0.0461 - val_acc: 0.9891 - val_ignore_accuracy: 0.8814\n",
            "Epoch 26/40\n",
            "2504/2504 [==============================] - 16s 6ms/step - loss: 0.0294 - acc: 0.9941 - ignore_accuracy: 0.9390 - val_loss: 0.0427 - val_acc: 0.9898 - val_ignore_accuracy: 0.8895\n",
            "Epoch 27/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0255 - acc: 0.9950 - ignore_accuracy: 0.9475 - val_loss: 0.0402 - val_acc: 0.9902 - val_ignore_accuracy: 0.8934\n",
            "Epoch 28/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0224 - acc: 0.9955 - ignore_accuracy: 0.9528 - val_loss: 0.0381 - val_acc: 0.9906 - val_ignore_accuracy: 0.8975\n",
            "Epoch 29/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0199 - acc: 0.9959 - ignore_accuracy: 0.9576 - val_loss: 0.0365 - val_acc: 0.9909 - val_ignore_accuracy: 0.9011\n",
            "Epoch 30/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0178 - acc: 0.9963 - ignore_accuracy: 0.9616 - val_loss: 0.0350 - val_acc: 0.9912 - val_ignore_accuracy: 0.9039\n",
            "Epoch 31/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0161 - acc: 0.9966 - ignore_accuracy: 0.9647 - val_loss: 0.0340 - val_acc: 0.9915 - val_ignore_accuracy: 0.9071\n",
            "Epoch 32/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0146 - acc: 0.9969 - ignore_accuracy: 0.9677 - val_loss: 0.0330 - val_acc: 0.9917 - val_ignore_accuracy: 0.9093\n",
            "Epoch 33/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0134 - acc: 0.9971 - ignore_accuracy: 0.9697 - val_loss: 0.0323 - val_acc: 0.9917 - val_ignore_accuracy: 0.9097\n",
            "Epoch 34/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0124 - acc: 0.9973 - ignore_accuracy: 0.9721 - val_loss: 0.0321 - val_acc: 0.9919 - val_ignore_accuracy: 0.9113\n",
            "Epoch 35/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0115 - acc: 0.9975 - ignore_accuracy: 0.9741 - val_loss: 0.0314 - val_acc: 0.9920 - val_ignore_accuracy: 0.9125\n",
            "Epoch 36/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0107 - acc: 0.9977 - ignore_accuracy: 0.9761 - val_loss: 0.0306 - val_acc: 0.9922 - val_ignore_accuracy: 0.9147\n",
            "Epoch 37/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0100 - acc: 0.9979 - ignore_accuracy: 0.9775 - val_loss: 0.0306 - val_acc: 0.9922 - val_ignore_accuracy: 0.9151\n",
            "Epoch 38/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0093 - acc: 0.9980 - ignore_accuracy: 0.9788 - val_loss: 0.0302 - val_acc: 0.9923 - val_ignore_accuracy: 0.9166\n",
            "Epoch 39/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0087 - acc: 0.9982 - ignore_accuracy: 0.9808 - val_loss: 0.0299 - val_acc: 0.9923 - val_ignore_accuracy: 0.9168\n",
            "Epoch 40/40\n",
            "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0082 - acc: 0.9982 - ignore_accuracy: 0.9812 - val_loss: 0.0298 - val_acc: 0.9924 - val_ignore_accuracy: 0.9174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U43wMAxy-ll0",
        "colab_type": "code",
        "outputId": "aa707b5d-68b3-450b-bf27-e089710666b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_samples = [\n",
        "    \"singing is my hobby .\".split(),\n",
        "    \"She was studying every week for a year .\".split()\n",
        "]\n",
        "print(test_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['singing', 'is', 'my', 'hobby', '.'], ['She', 'was', 'studying', 'every', 'week', 'for', 'a', 'year', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agbZFEqY93-F",
        "colab_type": "code",
        "outputId": "a59da9b1-2ad2-4f87-ad07-6fa6575ecacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "test_samples_X = []\n",
        "for s in test_samples:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        " \n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   1 5375 5233    1 5327    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0]\n",
            " [3219  757 2672 6488 9931 2831 8880 9973 5327    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z1f2ITf9_WU",
        "colab_type": "code",
        "outputId": "197f9719-47a9-44a8-d9fe-b53050c4f9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "print(predictions, predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[7.8720022e-03 1.0827631e-02 2.1617103e-04 ... 2.7352381e-01\n",
            "   3.6657455e-03 6.2896637e-05]\n",
            "  [3.3354718e-06 9.1246405e-04 1.0949839e-03 ... 1.8295063e-06\n",
            "   8.0726357e-05 3.2103391e-04]\n",
            "  [9.8364406e-05 1.8692419e-03 4.6534743e-04 ... 4.5884450e-04\n",
            "   1.1623140e-02 3.0030494e-03]\n",
            "  ...\n",
            "  [9.9998844e-01 1.0128198e-09 4.2514735e-11 ... 5.0886217e-10\n",
            "   7.9631135e-10 2.9319154e-09]\n",
            "  [9.9998283e-01 2.1384057e-09 1.0655595e-10 ... 5.2491417e-10\n",
            "   1.3060846e-09 8.1244060e-09]\n",
            "  [9.9997294e-01 4.4311017e-09 2.4459237e-10 ... 5.8346777e-10\n",
            "   2.1529294e-09 2.0349503e-08]]\n",
            "\n",
            " [[8.0319005e-06 1.3802830e-02 1.5102000e-03 ... 2.3775834e-03\n",
            "   8.1847963e-04 5.4658347e-05]\n",
            "  [7.1564011e-07 1.7370489e-04 9.6323283e-06 ... 4.4972057e-07\n",
            "   5.8691170e-05 6.1362043e-05]\n",
            "  [1.8270841e-04 7.2281633e-05 9.5876248e-06 ... 7.3228934e-04\n",
            "   1.9747106e-04 6.4861804e-04]\n",
            "  ...\n",
            "  [9.9998844e-01 1.0128141e-09 4.2514655e-11 ... 5.0886217e-10\n",
            "   7.9630524e-10 2.9318932e-09]\n",
            "  [9.9998283e-01 2.1383895e-09 1.0655555e-10 ... 5.2491417e-10\n",
            "   1.3060720e-09 8.1243439e-09]\n",
            "  [9.9997294e-01 4.4310764e-09 2.4459190e-10 ... 5.8346777e-10\n",
            "   2.1529087e-09 2.0349349e-08]]] (2, 271, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFLsksa7A8_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAv0AFJh8eJ2",
        "colab_type": "code",
        "outputId": "a4004bd9-407c-41d2-9365-f429f2da1baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
        "for i in tokens:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NNP', 'VBZ', 'PRP$', 'NN', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n",
            "['PRP', 'VBD', 'VBG', 'DT', 'NN', 'IN', 'DT', 'NN', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAz14faR8ZRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#singing is my hobby.\n",
        "#She was studying every week for a year."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
